{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deeksha-HL/Fcae-Detection-processing/blob/main/Face_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PnyEILBu8Zdv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75413a11-5125-49ca-b559-f6f5ca337ac6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/archive\"   # change if inside a folder\n",
        "print(os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "id": "FhkxxCvdGR4C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "654b3ea7-9bf5-41d2-fe90-29244902eecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/archive'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1294309254.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/archive\"\u001b[0m   \u001b[0;31m# change if inside a folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/archive'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn opencv-python tqdm\n"
      ],
      "metadata": {
        "id": "O8yQQZqqKeAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69a3d15-3e2a-46cf-fbf5-a3bd5858a3a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.92)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.3)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn) (1.5.3)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.12/dist-packages (from mtcnn) (4.4.5)\n",
            "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from mtcnn import MTCNN\n",
        "from tqdm import tqdm\n",
        "\n"
      ],
      "metadata": {
        "id": "lettr42RKhx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_path = \"/content/processed_dataset\"\n",
        "os.makedirs(processed_path, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "cWZ6VgUwKuU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = MTCNN()\n"
      ],
      "metadata": {
        "id": "iO4y5y2GL1I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, save_path):\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is None:\n",
        "        return\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = detector.detect_faces(image_rgb)\n",
        "\n",
        "    if results:\n",
        "        x, y, w, h = results[0]['box']\n",
        "\n",
        "        x, y = max(0, x), max(0, y)\n",
        "\n",
        "        face = image[y:y+h, x:x+w]\n",
        "\n",
        "        face = cv2.resize(face, (160, 160))\n",
        "\n",
        "        # ❌ REMOVE normalization here\n",
        "\n",
        "        cv2.imwrite(save_path, face)\n",
        "\n"
      ],
      "metadata": {
        "id": "6h5qrv5bL7wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/processed_dataset\n"
      ],
      "metadata": {
        "id": "vEX7m_kcb8j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(processed_path, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "fLLa5GGCcBDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for root, dirs, files in os.walk(dataset_path):\n",
        "\n",
        "    for file in tqdm(files):\n",
        "\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "\n",
        "            input_path = os.path.join(root, file)\n",
        "\n",
        "            # Maintain same folder structure\n",
        "            relative_path = os.path.relpath(root, dataset_path)\n",
        "            save_dir = os.path.join(processed_path, relative_path)\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "            save_path = os.path.join(save_dir, file)\n",
        "\n",
        "            preprocess_image(input_path, save_path)\n",
        "\n",
        "print(\"✅ All images processed successfully!\")\n"
      ],
      "metadata": {
        "id": "JJaskkXhMOkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/content\"))\n"
      ],
      "metadata": {
        "id": "ZN7AlA-ygV6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"/content/processed_dataset\"))\n"
      ],
      "metadata": {
        "id": "cDIAeVIngYfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(\"/content/processed_dataset\"):\n",
        "    for file in files:\n",
        "        if file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "            print(os.path.join(root, file))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "exV7NAzpgkcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBoMbPHdhc5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_image = \"/content/processed_dataset/Selfie & id data - public sample/10/archive_selfies/2_recent.jpeg\"\n",
        "img = cv2.imread(sample_image)\n",
        "\n",
        "\n",
        "if img is None:\n",
        "    print(\"Image not found!\")\n",
        "else:\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "6ocFOXjVhZW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8,1.2]\n",
        ")\n"
      ],
      "metadata": {
        "id": "sq_ufJUdjCbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceDetector:\n",
        "    \"\"\"MTCNN detector with Haar Cascade fallback.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        if cfg.USE_MTCNN:\n",
        "            try:\n",
        "                self.mtcnn = MTCNN()\n",
        "                self._mode = 'mtcnn'\n",
        "                print('  ✅  FaceDetector  →  MTCNN loaded')\n",
        "            except Exception as e:\n",
        "                print(f'   MTCNN failed ({e}), falling back to Haar')\n",
        "                self._mode = 'haar'\n",
        "        else:\n",
        "            self._mode = 'haar'\n",
        "\n",
        "        if self._mode == 'haar':\n",
        "            xml = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "            self.haar = cv2.CascadeClassifier(xml)\n",
        "            print('  ✅  FaceDetector  →  Haar Cascade loaded')\n",
        "\n",
        "    def detect(self, img_rgb):\n",
        "        \"\"\"Return (x,y,w,h), landmarks_dict or None, None.\"\"\"\n",
        "        if self._mode == 'mtcnn':\n",
        "            return self._mtcnn_detect(img_rgb)\n",
        "        return self._haar_detect(img_rgb), None\n",
        "\n",
        "    def _mtcnn_detect(self, img_rgb):\n",
        "        results = self.mtcnn.detect_faces(img_rgb)\n",
        "        if not results:\n",
        "            return None, None\n",
        "        best = max(results, key=lambda r: r['confidence'])\n",
        "        if best['confidence'] < cfg.MIN_CONFIDENCE:\n",
        "            return None, None\n",
        "        x, y, w, h = best['box']\n",
        "        x, y = max(0, x), max(0, y)\n",
        "        return (x, y, w, h), best['keypoints']\n",
        "\n",
        "    def _haar_detect(self, img_rgb):\n",
        "        gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "        faces = self.haar.detectMultiScale(gray, 1.1, 5, minSize=(60, 60))\n",
        "        if len(faces) == 0:\n",
        "            return None\n",
        "        return tuple(max(faces, key=lambda f: f[2] * f[3]))\n"
      ],
      "metadata": {
        "id": "fBJ0D9XRiCKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FHfiaFpxic-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}